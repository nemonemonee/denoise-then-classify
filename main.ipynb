{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "device = \"cuda\"\n",
    "# Transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "# Load the training and test datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.pool = nn.AvgPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=128,\n",
    "            nhead=8,\n",
    "            dim_feedforward=512,\n",
    "            dropout=.35,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.te = nn.TransformerEncoder(encoder_layer, num_layers=4)\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.te(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenoiseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoiseModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 3, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = torch.full((x.size(0), 1, x.size(2), x.size(3)), t, device=x.device, dtype=x.dtype)\n",
    "        x = torch.cat([x, t], dim=1)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier().to(device)\n",
    "opt_cls = optim.AdamW(classifier.parameters(), lr=5e-5)\n",
    "crt_cls = nn.CrossEntropyLoss()\n",
    "for epoch in range(1000):\n",
    "    running_loss = 0.0\n",
    "    train_size = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        train_size += len(data)\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        opt_cls.zero_grad()\n",
    "        outputs = classifier(inputs)\n",
    "        loss = crt_cls(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt_cls.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss /train_size :.3f}')\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = classifier(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_cls.pth'\n",
    "torch.save(classifier.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenoiseModel().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), 5e-4)\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 1000\n",
    "start_t = 0.3 \n",
    "end_t = 0.01 \n",
    "t_decrement = (start_t - end_t) / (num_epochs - 1)\n",
    "t = start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 170.143\n",
      "[2,     1] loss: 62.994\n",
      "[3,     1] loss: 59.190\n",
      "[4,     1] loss: 56.749\n",
      "[5,     1] loss: 54.815\n",
      "[6,     1] loss: 53.384\n",
      "[7,     1] loss: 51.840\n",
      "[8,     1] loss: 50.356\n",
      "[9,     1] loss: 48.889\n",
      "[10,     1] loss: 47.344\n",
      "[11,     1] loss: 45.848\n",
      "[12,     1] loss: 44.267\n",
      "[13,     1] loss: 43.005\n",
      "[14,     1] loss: 41.998\n",
      "[15,     1] loss: 41.305\n",
      "[16,     1] loss: 40.720\n",
      "[17,     1] loss: 40.367\n",
      "[18,     1] loss: 40.088\n",
      "[19,     1] loss: 39.854\n",
      "[20,     1] loss: 39.679\n",
      "[21,     1] loss: 39.580\n",
      "[22,     1] loss: 39.431\n",
      "[23,     1] loss: 39.316\n",
      "[24,     1] loss: 38.999\n",
      "[25,     1] loss: 38.568\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    train_size = 0\n",
    "    t = max(end_t, t - t_decrement)\n",
    "    for data in trainloader:\n",
    "        train_size += len(data)\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        noise = torch.randn_like(images) \n",
    "        noisy_images = images + noise * t\n",
    "        optimizer.zero_grad()\n",
    "        pred_noise = model(noisy_images, t)\n",
    "        loss = criterion(pred_noise, noise)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {1000 * running_loss / train_size :.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = None\n",
    "# denoiser = None\n",
    "\n",
    "num_epochs = 1000\n",
    "start_t = 0.3 \n",
    "end_t = 0.01 \n",
    "t_decrement = (start_t - end_t) / (num_epochs - 1)\n",
    "t = start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m train_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m     11\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m---> 12\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(images) \n\u001b[1;32m     14\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m images \u001b[38;5;241m+\u001b[39m noise \u001b[38;5;241m*\u001b[39m t\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "aug_cls = Classifier().to(device)\n",
    "\n",
    "opt_aug = optim.AdamW(aug_cls.parameters(), lr=5e-5)\n",
    "crt_aug = nn.CrossEntropyLoss()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    train_size = 0\n",
    "    t = max(end_t, t - t_decrement)\n",
    "    for i, data in enumerate(trainloader):\n",
    "        train_size += len(data)\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        noise = torch.randn_like(images) \n",
    "        noisy_images = images + noise * t\n",
    "        opt_aug.zero_grad()\n",
    "        outputs = aug_cls(images)\n",
    "        loss = crt_aug(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt_aug.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss /train_size :.3f}')\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = aug_cls(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
